{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,FunctionTransformer,PowerTransformer,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zon.winds</th>\n",
       "      <th>mer.winds</th>\n",
       "      <th>humidity</th>\n",
       "      <th>air temp.</th>\n",
       "      <th>s.s.temp.</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-109.44</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>88.293266</td>\n",
       "      <td>25.66</td>\n",
       "      <td>25.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-109.44</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>89.798431</td>\n",
       "      <td>25.69</td>\n",
       "      <td>25.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-109.44</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>89.044724</td>\n",
       "      <td>25.56</td>\n",
       "      <td>24.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-109.44</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>90.482239</td>\n",
       "      <td>24.72</td>\n",
       "      <td>23.64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-109.44</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.417183</td>\n",
       "      <td>24.66</td>\n",
       "      <td>24.34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  latitude  longitude  zon.winds  mer.winds   humidity  \\\n",
       "0  1980      3    8     -0.02    -109.44       -4.9        1.1  88.293266   \n",
       "1  1980      3    9     -0.02    -109.44       -4.5        2.2  89.798431   \n",
       "2  1980      3   10     -0.02    -109.44       -3.8        1.9  89.044724   \n",
       "3  1980      3   12     -0.02    -109.44       -4.4        0.3  90.482239   \n",
       "4  1980      3   13     -0.02    -109.44       -3.2        0.1  90.417183   \n",
       "\n",
       "   air temp.  s.s.temp.  time_elapsed  \n",
       "0      25.66      25.97             0  \n",
       "1      25.69      25.28             1  \n",
       "2      25.56      24.31             2  \n",
       "3      24.72      23.64             4  \n",
       "4      24.66      24.34             5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('updated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Scaler_pipeline=Pipeline(steps=[\\n    ('scaler',StandardScaler())\\n])\\n\\nlog_pipelie=Pipeline(steps=[\\n    ('log',FunctionTransformer(np.log1p,validate=True)),\\n    ('scaler',StandardScaler())\\n])\\n\\nboxcox_pipeline=Pipeline(steps=[\\n    ('boxcox',PowerTransformer(method='box-cox')),\\n    ('scaler',StandardScaler())\\n])\\n\\nyeojohnson_pipeline = Pipeline(steps=[\\n    ('yeojohnson', PowerTransformer(method='yeo-johnson')),\\n    ('scaler', StandardScaler())\\n])\\n\\npreprocessor=ColumnTransformer(transformers=[\\n    ('yeojohnso',yeojohnson_pipeline,['zon.winds']),\\n    ('log',log_pipelie,['air temp.']),\\n    ('scaler',Scaler_pipeline,(df.drop(columns=['zon.winds','air temp.','s.s.temp.'])).columns)\\n])\\n\\npreprocessed_data_1=preprocessor.fit_transform(df)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Scaler_pipeline=Pipeline(steps=[\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "log_pipelie=Pipeline(steps=[\n",
    "    ('log',FunctionTransformer(np.log1p,validate=True)),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "boxcox_pipeline=Pipeline(steps=[\n",
    "    ('boxcox',PowerTransformer(method='box-cox')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "yeojohnson_pipeline = Pipeline(steps=[\n",
    "    ('yeojohnson', PowerTransformer(method='yeo-johnson')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor=ColumnTransformer(transformers=[\n",
    "    ('yeojohnso',yeojohnson_pipeline,['zon.winds']),\n",
    "    ('log',log_pipelie,['air temp.']),\n",
    "    ('scaler',Scaler_pipeline,(df.drop(columns=['zon.winds','air temp.','s.s.temp.'])).columns)\n",
    "])\n",
    "\n",
    "preprocessed_data_1=preprocessor.fit_transform(df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data but not randomly, do it in a sequential order\n",
    "\n",
    "X_train=df[df['time_elapsed']<=5700].drop(columns=['s.s.temp.'])\n",
    "X_test=df[df['time_elapsed']>5700].drop(columns=['s.s.temp.'])\n",
    "y_train=df[df['time_elapsed']<=5700]['s.s.temp.']\n",
    "y_test=df[df['time_elapsed']>5700]['s.s.temp.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations and Scaling\n",
    "\n",
    "yeojohnson_transformer = PowerTransformer(method='yeo-johnson')\n",
    "X_train['zon.winds'] = yeojohnson_transformer.fit_transform(X_train[['zon.winds']])\n",
    "X_test['zon.winds'] = yeojohnson_transformer.transform(X_test[['zon.winds']])\n",
    "\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "X_train['ait temp.'] = log_transformer.fit_transform(X_train[['air temp.']])\n",
    "X_test['ait temp.'] = log_transformer.transform(X_test[['air temp.']])\n",
    "\n",
    "excluded_columns = ['zon.winds', 'air.temp.']\n",
    "columns_to_scale = [col for col in X_train.columns if col not in excluded_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3_original\\envs\\py310\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\Dell\\anaconda3_original\\envs\\py310\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MSE: 0.31259299753524306\n",
      "ARIMA MSE: 5.463117895016913\n",
      "XGBoost Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300}\n",
      "ARIMA Best Parameters: {'order': (4, 2, 3)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# Load your sea surface temperature (SST) data\n",
    "# Define X_train, X_test, y_train, y_test\n",
    "\n",
    "# Define custom estimator for ARIMA\n",
    "class ARIMAWrapper(BaseEstimator):\n",
    "    def __init__(self, order):\n",
    "        self.order = order\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = ARIMA(y, order=self.order)\n",
    "        self.model_fit = self.model.fit()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_fit.forecast(steps=len(X))\n",
    "\n",
    "# Define parameters for hyperparameter tuning\n",
    "xgb_param_grid = {'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 5, 7], 'n_estimators': [100, 200, 300]}\n",
    "arima_param_grid = {'order': [(p, d, q) for p in range(6) for d in range(3) for q in range(6)]}\n",
    "\n",
    "# Perform hyperparameter tuning for XGBoost\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "xgb_best_params = xgb_grid_search.best_params_\n",
    "\n",
    "# Perform hyperparameter tuning for ARIMA\n",
    "arima_model = ARIMAWrapper(order=(1, 1, 1))  # Example order, change as needed\n",
    "arima_grid_search = GridSearchCV(estimator=arima_model, param_grid=arima_param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "arima_grid_search.fit(X_train, y_train)  # Assuming univariate time series\n",
    "arima_best_params = arima_grid_search.best_params_\n",
    "\n",
    "# Evaluate models\n",
    "# Assuming X_test and y_test are available\n",
    "xgb_best_model = XGBRegressor(**xgb_best_params)\n",
    "xgb_best_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_best_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "\n",
    "best_arima_order = arima_best_params['order']\n",
    "arima_model = ARIMAWrapper(order=best_arima_order)\n",
    "arima_model.fit(X_train, y_train)\n",
    "y_pred_arima = arima_model.predict(X_test)\n",
    "mse_arima = mean_squared_error(y_test, y_pred_arima)\n",
    "\n",
    "print(\"XGBoost MSE:\", mse_xgb)\n",
    "print(\"ARIMA MSE:\", mse_arima)\n",
    "\n",
    "print(\"XGBoost Best Parameters:\", xgb_best_params)\n",
    "print(\"ARIMA Best Parameters:\", arima_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score xgb: 0.9402444699031923\n",
      "R² Score arima: -0.04433403298257321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_squared_xgb = r2_score(y_test, y_pred_xgb)\n",
    "r_squared_arima=r2_score(y_test,y_pred_arima)\n",
    "print(\"R² Score xgb:\", r_squared_xgb)\n",
    "print(\"R² Score arima:\", r_squared_arima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
